{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-agency",
   "metadata": {},
   "source": [
    "# Private 2nd Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-elder",
   "metadata": {},
   "source": [
    "원래 코드: https://dacon.io/competitions/official/235689/codeshare/2396?page=2&dtype=recent\n",
    "\n",
    "ghghdfd 님의 tensorflow 코드를 pytorch로 재구현합니다.\n",
    "\n",
    "\n",
    "- Pre-Learning 부분은 동일합니다.\n",
    "\n",
    "    - 이에 대한 분석은 분석은 Review.pdf에서 확인하실 수 있습니다.\n",
    "\n",
    "- Data Modeling 부분을 재구현하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-arbitration",
   "metadata": {},
   "source": [
    "### Pre-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from numpy.fft import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-marijuana",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./open/train_features.csv')\n",
    "train_labels=pd.read_csv('./open/train_labels.csv')\n",
    "test=pd.read_csv('./open/test_features.csv')\n",
    "\n",
    "submission=pd.read_csv('./open/sample_submission.csv')\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-subject",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "russian-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy']=(train['acc_x']**2+train['acc_y']**2+train['acc_z']**2)**(1/3)\n",
    "test['acc_Energy']=(test['acc_x']**2+test['acc_y']**2+test['acc_z']**2)**(1/3)\n",
    "\n",
    "train['gy_Energy']=(train['gy_x']**2+train['gy_y']**2+train['gy_z']**2)**(1/3)\n",
    "test['gy_Energy']=(test['gy_x']**2+test['gy_y']**2+test['gy_z']**2)**(1/3)\n",
    "\n",
    "train['gy_acc_Energy']=((train['gy_x']-train['acc_x'])**2+(train['gy_y']-train['acc_y'])**2+(train['gy_z']-train['acc_z'])**2)**(1/3)\n",
    "test['gy_acc_Energy']=((test['gy_x']-test['acc_x'])**2+(test['gy_y']-test['acc_y'])**2+(test['gy_z']-test['acc_z'])**2)**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.02 \n",
    "def jerk_signal(signal): \n",
    "        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "professional-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:33<00:00, 93.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dt=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    train_dt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behavioral-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 782/782 [00:06<00:00, 117.63it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dt=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    test_dt.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-accounting",
   "metadata": {},
   "source": [
    "푸리에 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accurate-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from numpy.fft import *\n",
    "\n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saved-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat(train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ethical-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:12<00:00, 243.81it/s]\n"
     ]
    }
   ],
   "source": [
    "fft=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for i in train.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft.append(temp)\n",
    "train=pd.concat(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedicated-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat(test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "neutral-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 782/782 [00:01<00:00, 511.47it/s]\n"
     ]
    }
   ],
   "source": [
    "fft_t=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for i in test.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft_t.append(temp)\n",
    "test=pd.concat(fft_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-nerve",
   "metadata": {},
   "source": [
    "standard scailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "realistic-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=train.columns\n",
    "train_s=train.copy()\n",
    "test_s=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "involved-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_s.iloc[:,2:]= scaler.fit_transform(train_s.iloc[:,2:])\n",
    "train_sc = pd.DataFrame(data = train_s,columns =col) \n",
    "# numpy 형태로 변형되어, 모델 돌리기 쉽게 하려고 DF로 변경\n",
    "\n",
    "test_s.iloc[:,2:]= scaler.transform(test_s.iloc[:,2:])\n",
    "test_sc = pd.DataFrame(data = test_s,columns =col)\n",
    "# numpy 형태로 변형되어, 모델 돌리기 쉽게 하려고 다시 DF로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "traditional-world",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.356382</td>\n",
       "      <td>8.807207</td>\n",
       "      <td>19.465910</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.869226</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>-0.272719</td>\n",
       "      <td>-0.276391</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.833464</td>\n",
       "      <td>0.820412</td>\n",
       "      <td>-0.282128</td>\n",
       "      <td>-0.093560</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.742974</td>\n",
       "      <td>-0.236152</td>\n",
       "      <td>-0.240632</td>\n",
       "      <td>0.416836</td>\n",
       "      <td>-0.118821</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.349095</td>\n",
       "      <td>0.377085</td>\n",
       "      <td>0.564992</td>\n",
       "      <td>0.166566</td>\n",
       "      <td>0.162871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.315921</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.182551</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.819822</td>\n",
       "      <td>-0.169815</td>\n",
       "      <td>-0.173080</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>-0.531727</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>-0.202368</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.175645</td>\n",
       "      <td>0.300944</td>\n",
       "      <td>0.306341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.117634</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>-0.035229</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>-0.058780</td>\n",
       "      <td>-0.213920</td>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>-0.385106</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.077915</td>\n",
       "      <td>0.609008</td>\n",
       "      <td>0.599518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151477</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>-0.350724</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.791528</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.259227</td>\n",
       "      <td>-0.055206</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.259626</td>\n",
       "      <td>0.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>0.112282</td>\n",
       "      <td>-0.138940</td>\n",
       "      <td>0.829394</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.027804</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.142794</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>0.063674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>10.220817</td>\n",
       "      <td>5.476964</td>\n",
       "      <td>7.441373</td>\n",
       "      <td>3.605246</td>\n",
       "      <td>16.530576</td>\n",
       "      <td>11.843241</td>\n",
       "      <td>-0.167578</td>\n",
       "      <td>0.814816</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.150658</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.265559</td>\n",
       "      <td>-0.027936</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.065316</td>\n",
       "      <td>-0.064300</td>\n",
       "      <td>-0.062949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.177768</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>-0.192468</td>\n",
       "      <td>-0.033904</td>\n",
       "      <td>-0.227861</td>\n",
       "      <td>-0.151875</td>\n",
       "      <td>0.802027</td>\n",
       "      <td>0.797338</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>-0.049283</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>-0.152712</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>-0.056225</td>\n",
       "      <td>-0.053918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>0.728823</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>1.281790</td>\n",
       "      <td>0.403540</td>\n",
       "      <td>-0.175811</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.797431</td>\n",
       "      <td>0.174681</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>-0.014412</td>\n",
       "      <td>-0.049662</td>\n",
       "      <td>-0.054574</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>0.886204</td>\n",
       "      <td>0.075614</td>\n",
       "      <td>1.107553</td>\n",
       "      <td>-0.182228</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>-0.223043</td>\n",
       "      <td>0.803421</td>\n",
       "      <td>0.799233</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>-0.107081</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>-0.042034</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.009633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.495681  -0.272719      -0.276391  0.000027  0.000298   \n",
       "1         0.011266    0.742974  -0.236152      -0.240632  0.416836 -0.118821   \n",
       "2        -0.003708    0.819822  -0.169815      -0.173080  0.086405  0.023750   \n",
       "3         0.005408    0.785669  -0.035229      -0.040560 -0.058780 -0.213920   \n",
       "4         0.154354    0.791528   0.021954       0.016872  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.138940   0.829394       0.823900  0.151679  0.037205   \n",
       "1874996  11.843241   -0.167578   0.814816       0.809618  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.151875   0.802027       0.797338  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.175811   0.801880       0.797431  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.223043   0.803421       0.799233  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000101      0.001505   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.564992      0.166566   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.175645      0.300944   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.077915      0.609008   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.013483      0.259626   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.142794      0.063329   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.065316     -0.064300   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.035970     -0.056225   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.054574      0.000843   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.107792      0.008458   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001501  \n",
       "1                0.162871  \n",
       "2                0.306341  \n",
       "3                0.599518  \n",
       "4                0.260669  \n",
       "...                   ...  \n",
       "1874995          0.063674  \n",
       "1874996         -0.062949  \n",
       "1874997         -0.053918  \n",
       "1874998          0.001922  \n",
       "1874999          0.009633  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-guest",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "corporate-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bronze-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "optical-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aerial-cartoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 18, 600)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(train_sc.iloc[:,2:]).reshape(-1, 18, 600)\n",
    "X.shape\n",
    "np.transpose(X, (1, 0, 2))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "normal-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 18, 600)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=np.array(test_sc.iloc[:,2:]).reshape(-1, 18, 600)\n",
    "test_x.shape\n",
    "np.transpose(test_x, (1, 0, 2))\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faced-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(18, 128, kernel_size=9, padding = 4, stride=1),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3))\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(128, 256, kernel_size=7, padding = 3, stride=1),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.4))\n",
    "            \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(256, 128, kernel_size=3, padding = 1, stride=1),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "\n",
    "        return out \n",
    "        # return self.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "convinced-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_model(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(18, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(128, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "reflected-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "universal-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "organizational-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "canadian-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "convertible-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_labels['label'].values\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]\n",
    "\n",
    "y = to_categorical(train_labels['label'], 61)\n",
    "\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "graduate-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 2021, shuffle = True)\n",
    "reLR = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 4, verbose = True)\n",
    "# reLR = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 4,verbose = 1,factor = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "interracial-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorchtools import EarlyStopping\n",
    "# es = EarlyStopping(monitor='val_loss', patience=8, model='min')\n",
    "# 왜인지 모르겠지만 pytorchtools에서 EarlyStopping을 import할 수 없으므로\n",
    "# 직접 구현한 코드 들고 옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "transsexual-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "casual-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-31a9a0ecef41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0moptimzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, training_epochs):\n",
    "    \n",
    "    print(f'Starting epoch {epoch + 1}')\n",
    "    current_loss = 0.0\n",
    "\n",
    "    for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n",
    "        \n",
    "        inputs, targets = data\n",
    "        optimzer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "            \n",
    "    print('Training process has finished. Saving trained model.')\n",
    "    print('Starting testing')\n",
    "    \n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        inputs, targets = data\n",
    "        outputs = network(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "    print('--------------------------------')\n",
    "    results[fold] = 100.0 * (correct / total)\n",
    "        \n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "        print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "handmade-thesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Fold_1--------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'cnn_model' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-6899f803d58f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"Fold_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n\u001b[0m\u001b[0;32m     13\u001b[0m                         verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./model_kf/cv_study{i + 1}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cnn_model' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping\n",
    "# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, mode='min')\n",
    "\n",
    "accuracy = []\n",
    "losss=[]\n",
    "models=[]\n",
    "\n",
    "for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(f'./model_kf/cv_study{i + 1}.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)\n",
    "    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n",
    "    model = cnn_model()\n",
    "    \n",
    "    \n",
    "    history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n",
    "                        verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n",
    "    \n",
    "    \n",
    "    model.load_weights(f'./model_kf/cv_study{i + 1}.h5')\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[validation], y[validation])[1])\n",
    "    k_loss = '%.4f' % (model.evaluate(X[validation], y[validation])[0])\n",
    "    \n",
    "    accuracy.append(k_accuracy)\n",
    "    losss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation loss: {}'.format(losss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-listening",
   "metadata": {},
   "source": [
    "기타 참고\n",
    "\n",
    "\n",
    "- pytorch에서 EarlyStop 이용하기\n",
    "    - https://quokkas.tistory.com/entry/pytorch%EC%97%90%EC%84%9C-EarlyStop-%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0\n",
    "\n",
    "\n",
    "- pytorch가 제공하는 Learning rate scheduler 정리 - ReduceLROnPlateau\n",
    "    - https://sanghyu.tistory.com/113\n",
    "    \n",
    "    \n",
    "- torch.optim.lr_scheduler.ReduceLROnPlateau 사용법\n",
    "    - https://pytorch.org/docs/stable/optim.html\n",
    "    \n",
    "    \n",
    "- 검증(validation) 추가하고 fit()와 get_data() 생성하기\n",
    "    - https://deep-learning-study.tistory.com/351"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
